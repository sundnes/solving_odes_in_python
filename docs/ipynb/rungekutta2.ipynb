{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d85f6d",
   "metadata": {},
   "source": [
    "# Stable solvers for stiff ODEs\n",
    "\n",
    "\n",
    "In the previous chapter we introduced explicit Runge-Kutta (ERK) methods and observed\n",
    "how they could conveniently be implemented as a hierarchy of Python classes. For most\n",
    "ODE systems, replacing the simple forward Euler method with a higher-order ERK method\n",
    "will significantly reduce the number of time steps needed to reach a \n",
    "specified accuracy. In most cases it will also lead to a reduced overall computation time,\n",
    "since the additional cost for each time step is more than outweighed by the reduced number \n",
    "of steps. However, for a certain class of ODEs we may observe that all the ERK methods require\n",
    "very small time steps, and any attempt to increase the time step will lead to spurious\n",
    "oscillations and possible divergence of the solution. These ODE systems are usually\n",
    "referred to as *stiff*, and none of the explicit methods introduced in the previous\n",
    "chapters do a very good job at solving them. We shall see that implicit solvers such as\n",
    "implicit Runge-Kutta (IRK) methods are far better suited for stiff problems, and may give\n",
    "substantial reduction of the computation time for challenging problems.\n",
    "\n",
    "# Stiff ODE systems and stability\n",
    "<div id=\"sec:stab_analysis\"></div>\n",
    "One very famous example of a stiff ODE system is the Van der Pol equation, which can be \n",
    "written as an initial value problem on the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bfd73",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"vdp1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "y_1' = y_2, \\quad y_1(0) = 1, \\label{vdp1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc86c1",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"vdp2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "y_2' = \\mu(1-y_1^2)y_2 - y_1, \\quad  y_2(0) = 0. \\label{vdp2} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcefa1",
   "metadata": {},
   "source": [
    "The parameter $\\mu$ is a constant which determines the properties of the system, including \n",
    "its \"stiffness\". For $\\mu=0$ the problem is a simple oscillator with analytical solution\n",
    "$y_1 = \\cos(t),y_2=\\sin(t)$, while for non-zero values of $\\mu$ the solution shows\n",
    "far more complex behavior. The following code implements this system and solves it with the\n",
    "`ForwardEuler` subclass of the `ODESolver` class hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "579f14de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from ODESolver import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class VanderPol:\n",
    "    def __init__(self,mu):\n",
    "        self.mu = mu\n",
    "\n",
    "    def __call__(self,t,u):\n",
    "        du1 = u[1]\n",
    "        du2 = self.mu*(1-u[0]**2)*u[1]-u[0]\n",
    "        return du1,du2\n",
    "\n",
    "model = VanderPol(mu=1)\n",
    "\n",
    "solver = ForwardEuler(model)\n",
    "solver.set_initial_condition([1,0])\n",
    "\n",
    "t,u  = solver.solve(t_span=(0,20),N=1000)\n",
    "\n",
    "plt.plot(t,u)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855a42a",
   "metadata": {},
   "source": [
    "[Figure](#fig:vanderpol) shows the solutions for $\\mu=0,1$ and 5. Setting $\\mu$ even higher, for instance\n",
    "$\\mu=50$, leads to a divergent (unstable) solution with the time step used here ($\\Delta t = 0.02$). \n",
    "Replacing the FE method with one of the more\n",
    "accurate ERK method may help a little, but not much. It does help to reduce the time step dramatically, \n",
    "but the resulting computation time may be substantial. The time step for this problem is dictated by \n",
    "stability requirements rather than our desired accuracy, and there may be significant gains \n",
    "from choosing a solver that is more stable than the ERK methods considered so far. \n",
    "\n",
    "<!-- dom:FIGURE: [./figs_ch3/vanderpol1.png, width=600 frac=1] Solutions of the Van der Pol model for different values of $\\mu$. <div id=\"fig:vanderpol\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:vanderpol\"></div>\n",
    "\n",
    "<p>Solutions of the Van der Pol model for different values of $\\mu$.</p>\n",
    "<img src=\"./figs_ch3/vanderpol1.png\" width=600>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "Why does the solution of the Van der Pol model fail so badly for large values of $\\mu$? And, more generally,\n",
    "what are the properties of an ODE system that makes it stiff? To answer these questions, it is useful to \n",
    "start with a simpler problem than the Van der Pol model.  \n",
    "Consider, for instance, a simple IVP known as the Dahlquist test equation;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916dc7e",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"linear\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u' = \\lambda u, \\quad u(0) = 1,  \\label{linear} \\tag{3} \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7be1b",
   "metadata": {},
   "source": [
    "where $\\lambda$ may be a complex number. With $\\lambda = 1$ this is the simple exponential growth \n",
    "problem considered earlier, but in this chapter we are primarily interested in $\\lambda$ with negative\n",
    "real part, i.e., either real or complex $\\lambda$ that satisfy $\\Re(\\lambda) < 0$. \n",
    "In such cases the solution of ([3](#linear)) decays over time and is completely stable, \n",
    "but we shall see that the numerical solutions do not always retain this property.\n",
    "\n",
    "Following the definition in [[AscherPetzold]](#AscherPetzold), we say that problem ([3](#linear)) is stiff for an interval\n",
    "$[0,b]$ if the real part of $\\lambda$ satisfies\n",
    "\\[\n",
    "b\\Re(\\lambda) \\ll -1 .\n",
    "\\]\n",
    "For more general non-linear\n",
    "problems, such as the Van der Pol model in ([1](#vdp1))-([2](#vdp2)), the\n",
    "system's stiffness is characterized by the eigenvalues $\\lambda_i$ of the local\n",
    "Jacobian matrix $J$ of the right-hand side function $f$. The Jacobian is defined by \n",
    "\\[\n",
    "J_{ij} = \\frac{\\partial f_i (t,y)}{\\partial y_j} ,\n",
    "\\]\n",
    "and the problem is stiff for an interval $[0,b]$ if\n",
    "\\[\n",
    "b\\min_{i}\\Re(\\lambda_i) \\ll -1.\n",
    "\\]\n",
    "In the ODE literature one will also find more pragmatic definitions\n",
    "of stiffness, for instance that an equation is stiff if the \n",
    "time step needed to maintain stability of an explicit\n",
    "method is much smaller than the time step dictated by the accuracy\n",
    "requirements [[Curtiss52;@AscherPetzold]](#Curtiss52;@AscherPetzold). These definitions indicate that\n",
    "the stiffness of a problem is not only a function of the ODE itself,\n",
    "but also of the interval of integration and of the chosen accuracy requirement. A\n",
    "detailed discussion of stiff ODE systems can be found in, for instance,\n",
    "[[AscherPetzold;@ODEII]](#AscherPetzold;@ODEII).\n",
    "\n",
    "Eq. ([3](#linear)) is the foundation for *linear stability analysis*, which is a very\n",
    "useful technique for analyzing and understanding the stability of ODE solvers. \n",
    "The solution to the equation is $u(t) = e^{\\lambda t}$, which obviously grows\n",
    "very rapidly if $\\lambda$ with a positive real part. We are therefore primarily \n",
    "interested in the case $\\Re(\\lambda) < 0$, for which the analytical solution is stable, but \n",
    "our choice of solver may introduce *numerical instabilities*. The\n",
    "Forward Euler method applied to ([3](#linear)) gives the update formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f3642",
   "metadata": {},
   "source": [
    "$$\n",
    "u_{n+1} = u_n +\\Delta t \\lambda u_n = u_n (1+\\Delta t \\lambda) ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b1c058",
   "metadata": {},
   "source": [
    "and for the first step, since we have $u(0) = 1$, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bac102",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"linear_euler1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    u_1 = u(\\Delta t) =  1+\\Delta t \\lambda . \\label{linear_euler1} \\tag{4}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e49a7",
   "metadata": {},
   "source": [
    "The analytical solution decays exponentially for $\\Re(\\lambda) < 0$, and it is natural to \n",
    "require the same behavior of the numerical solution, and this gives the requirement\n",
    "that $| 1+\\Delta t \\lambda | \\leq 1$. If $\\lambda$ is real and negative, the time\n",
    "step must be chosen to satisfy $\\Delta t \\leq -2/\\lambda$ to ensure stability. Keep in mind that\n",
    "this criterion does not necessarily give a very accurate solution, and it may even oscillate and\n",
    "look completely different from the exact solution. However, choosing $\\Delta t$ to satisfy \n",
    "the stability criterion ensures that the solution, as well as any spurious oscillations \n",
    "and other numerical artefacts, decay with time.\n",
    "\n",
    "We have observed that the right-hand side of ([4](#linear_euler1)) contains critical information\n",
    "about the stability of the FE method. This expression is often called the \n",
    "*stability function* or the *amplification factor* of the method, and is written on the general form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10662c4b",
   "metadata": {},
   "source": [
    "$$\n",
    "R(z) = 1+z .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740f351",
   "metadata": {},
   "source": [
    "The FE method is stable for all values $\\lambda \\Delta t$ which give $\\|R(\\lambda \\Delta t)\\| <1$,\n",
    "and this region of $\\lambda \\Delta t$ values in the complex plane is referred to as the method's\n",
    "*region of absolute stability*, or simply its *stability region*. \n",
    "The stability region for the FE method is shown in the left panel of [Figure](#fig:stab_erk). The stability\n",
    "domain is a circle with center $(-1,1)$ and radius one. Obviously, \n",
    "if $\\lambda \\ll 0$, require $\\lambda \\Delta t$ to lie within this circle is quite restrictive for the choice of $\\Delta t$. \n",
    "\n",
    "<!-- dom:FIGURE: [./figs_ch3/stab_region_erk.png, width=800 frac=1] Stability regions for explicit Runge-Kutta methods. From left: forward Euler, explicit midpoint, and the fourth order method given by ([rk4_0](#rk4_0))-([rk4_5](#rk4_5)). <div id=\"fig:stab_erk\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:stab_erk\"></div>\n",
    "\n",
    "<p>Stability regions for explicit Runge-Kutta methods. From left: forward Euler, explicit midpoint, and the fourth order method given by ([rk4_0](#rk4_0))-([rk4_5](#rk4_5)).</p>\n",
    "<img src=\"./figs_ch3/stab_region_erk.png\" width=800>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "We can easily extend the linear stability analysis to the other explicit RK methods introduced in Chapter 2.\n",
    "For instance, applying a single step of the explicit midpoint method given by ([midpoint0](#midpoint0))-([midpoint2](#midpoint2)) to \n",
    "([3](#linear)) gives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b010044",
   "metadata": {},
   "source": [
    "$$\n",
    "u(\\Delta t)  = 1 + \\lambda\\Delta t + \\frac{(\\Delta t\\lambda)^2}{2} ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1681488c",
   "metadata": {},
   "source": [
    "and we identify the stability function for this method as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ddf93",
   "metadata": {},
   "source": [
    "$$\n",
    "R(z) = 1 + z + \\frac{z^2}{2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2a153",
   "metadata": {},
   "source": [
    "The corresponding stability region is shown in the middle panel of [Figure](#fig:stab_erk). For the \n",
    "fourth order RK method defined in ([rk4_0](#rk4_0))-([rk4_5](#rk4_5)), the same steps reveal that the stability function is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c45b3",
   "metadata": {},
   "source": [
    "$$\n",
    "R(z) = 1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80599a9e",
   "metadata": {},
   "source": [
    "and the stability region is shown in the right panel of [Figure](#fig:stab_erk). We observe\n",
    "that the stability regions of the two higher-order RK methods are larger than that of the FE method, but not much. In fact, \n",
    "if we consider the computational cost of each time step for these methods, the FE method is usually superior \n",
    "for problems where the time step is governed by stability. \n",
    "\n",
    "It can be shown that the stability function\n",
    "for an $s$-stage explicit RK method is always a polynomial of degree $\\leq s$, and it can easily be verified that\n",
    "the stability region defined by such a polynomial will never be very large. To obtain a significant \n",
    "improvement of this situation, we typically need to replace the explicit methods considered so far with implicit RK methods.\n",
    "\n",
    "# Implicit methods for stability\n",
    "Since ([3](#linear)) is stable for all values of $\\lambda$ with a negative real part, it is natural to look\n",
    "for numerical methods with the same property. This means that the stability domain for the method \n",
    "covers the entire left half of the complex plane, or that its stability function $|R(z)|\\leq 1$ whenever $\\Re(z) \\leq 0$. \n",
    "This property is called *A-stability*. As noted above, the stability \n",
    "function of an explicit RK method is always a polynomial, and no polynomial satisfies $|R(z)|< 1$ for all $z<0$. \n",
    "Therefore, there are no A-stable explicit RK methods. \n",
    "An even  stronger stability requirement can be motivated \n",
    "by the fact that for $\\lambda \\ll 0$, the solution to ([3](#linear)) decays very rapidly. It is natural to expect the same\n",
    "behavior of the numerical solution, by requiring $|R(z)|\\rightarrow 0$ as $z\\rightarrow -\\infty$. This property is \n",
    "referred to as *stiff decay*, and an A-stable method that also has stiff decay is called an *L-stable* method. \n",
    "\n",
    "The simplest implicit RK method is the backward Euler (BE) method, which can be derived in exactly the same way \n",
    "as the FE method, by approximating the derivative with a simple finite difference. The only difference\n",
    "from the FE method is that the right-hand side is evaluated at step $n+1$ rather than step $n$. \n",
    "For a general ODE, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da7f102",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{u_{n+1}-u_n}{\\Delta t} = f(t_{n+1},u_{n+1}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef757a",
   "metadata": {},
   "source": [
    "and if we rearrange the terms we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341626e",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"be_nonlin0\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u_{n+1} - \\Delta t f(t_{n+1},u_{n+1}) = u_n  .  \\label{be_nonlin0} \\tag{5}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c6cb9",
   "metadata": {},
   "source": [
    "Although the derivation is very similar to the FE method, there is a \n",
    "fundamental difference in that the unknown $u_{n+1}$ occurs as an argument in the right-hand \n",
    "side function $f(t,u)$. Therefore, for nonlinear $f$, ([5](#be_nonlin0)) is a \n",
    "nonlinear algebraic equation that must be solved for the unknown $u_{n+1}$, \n",
    "instead of the explicit update formula we had for the FE method. This requirement \n",
    "makes implicit methods more complex to implement than explicit methods, and they tend to \n",
    "require far more computations per time step. Still, as we will demonstrate later, the\n",
    "superior stability properties still make implicit solvers better suited for stiff problems. \n",
    "\n",
    "We will consider the implementation of implicit solvers \n",
    "in the section [Implementing implicit Runge-Kutta methods](#sec:irk_simple_impl) below, but\n",
    "let us first study the stability of the BE method and other implicit RK solvers using the\n",
    "linear stability analysis introduced above. Applying the \n",
    "BE method to ([3](#linear)) yields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f4f5b0",
   "metadata": {},
   "source": [
    "$$\n",
    "u_{n+1} (1-\\Delta t\\lambda) = u_n,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519ddb6",
   "metadata": {},
   "source": [
    "and for the first time step, with $u(0) = 1$, we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd16da",
   "metadata": {},
   "source": [
    "$$\n",
    "u_1 = \\frac{1}{1-\\Delta t\\lambda} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6c69e",
   "metadata": {},
   "source": [
    "The stability function of the BE method is therefore $R(z) = 1/(1-z)$, and the corresponding stability domain is \n",
    "shown in the left panel of [Figure](#fig:stab_irk0). The method is stable for all choices of $\\lambda \\Delta t$\n",
    "*outside* the circle with radius one and center at (1,0) in the complex plane, confirming that the BE \n",
    "is a very stable method. It is A-stable, since the stability domain covers the entire left half of the\n",
    "complex plane, and it is also L-stable since the stability function satisfies \n",
    "$R(z) \\rightarrow 0$ as $\\Re(z) \\rightarrow -\\infty$.\n",
    "\n",
    "<!-- dom:FIGURE: [./figs_ch3/stab_region_irk0.png, width=800 frac=1] Stability regions for the backward Euler method (left) and the implicit midpoint method and trapezoidal method (right).  <div id=\"fig:stab_irk0\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:stab_irk0\"></div>\n",
    "\n",
    "<p>Stability regions for the backward Euler method (left) and the implicit midpoint method and trapezoidal method (right).</p>\n",
    "<img src=\"./figs_ch3/stab_region_irk0.png\" width=800>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "The BE method fits into the general RK framework defined by ([genrk0](#genrk0))-([genrk1](#genrk1)) in Chapter \n",
    "2, with a single stage ($s=1$), and $a_{11} = b_1 = c_1 = 1$. \n",
    "As for the FE method considered in Chapter 2, we can reformulate the method slightly\n",
    "to introduce a stage derivative and make it obvious that the BE method is part of the RK family:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99866aa",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"backward_euler0\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    k_1 = f(t_n+\\Delta t,u_n+\\Delta t k_1), \\label{backward_euler0} \\tag{6}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98edbd",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"backward_euler1\"></div> <div id=\"imp_midpoint0\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "    u_{n+1} = u_n + \\Delta t k_1 . \\label{backward_euler1} \\tag{7}\n",
    "\\end{equation}\n",
    "idx{midpoint method !implicit} idx{trapezoidal method ! implicit} idx{Crank-Nicolson method}\n",
    "The explicit midpoint and\n",
    "trapezoidal methods mentioned above also have their implicit counterparts. The implicit midpoint method\n",
    "is given by\n",
    "\\begin{equation}\n",
    "    k_1 = f(t_n+\\Delta t/2,u_n + k_1 \\Delta t/2), \\label{imp_midpoint0} \\tag{8} \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d269c2d",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"imp_midpoint1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "    u_{n+1} = u_n + \\Delta t k_1, \\label{imp_midpoint1} \\tag{9}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a0c3b",
   "metadata": {},
   "source": [
    "while the implicit trapezoidal rule, or Crank-Nicolson method, is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f39f78",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"cn_0\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "k_1 = f(t_n,u_n), \\label{cn_0} \\tag{10}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284409d8",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"cn_1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "k_2 = f(t_n+\\Delta t,u_n+\\Delta t k_2), \\label{cn_1} \\tag{11}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e19505",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"cn_2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "u_{n+1} = u_n + \\frac{\\Delta t}{2} (k_1 +k_2) . \\label{cn_2} \\tag{12}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecb2c76",
   "metadata": {},
   "source": [
    "Note that this formulation of the Crank-Nicolson is not very common, and can be simplified\n",
    "considerably by eliminating the stage derivatives and defining the method in terms\n",
    "of $u_n$ and $u_{n+1}$. However, the formulation in ([10](#cn_0))-([12](#cn_2)) is convenient\n",
    "for highlighting that it is in fact an implicit RK method. \n",
    "The implicit nature of the simple methods above is apparent from the formulas; one of the stage derivatives \n",
    "must be computed by solving an equation involving the non-linear function $f$ rather than from an \n",
    "explicit update formula. The Butcher tableaus of the three methods are given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c1ebe",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"irk_butcher0\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{array}{c|c}\n",
    "1 & 1 \\\\ \\hline\n",
    " & 1\n",
    "\\end{array} ,\\hspace{0.5cm}\n",
    "\\begin{array}{c|c}\n",
    "    1/2 & 1/2 \\\\ \\hline\n",
    "     & 1\n",
    "    \\end{array} ,\\hspace{0.5cm}\n",
    "\\begin{array}{c|cc}\n",
    "    0 & & \\\\\n",
    "    1 & 0 & 1 \\\\ \\hline\n",
    "     & 1/2 & 1/2\n",
    "    \\end{array} ,\\hspace{0.5cm}\n",
    "\\label{irk_butcher0} \\tag{13}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ef5f6",
   "metadata": {},
   "source": [
    "from left to right for backward Euler, implicit midpoint and the implicit trapezoidal method. \n",
    "\n",
    "The implicit midpoint method is and the implicit trapezoidal method have the\n",
    "same stability function, given by $R(z) = (2+z)/(2-z)$. The corresponding stability domain covers\n",
    "the entire left half-plane of the complex plane, shown in the right panel of [Figure](#fig:stab_irk0).\n",
    "Both the implicit midpoint method and the trapezoidal method are therefore A-stable methods. However,\n",
    "we have $R(z)\\rightarrow 1$ as $z\\rightarrow -\\infty$, so the methods do not have stiff decay \n",
    "and are therefore not L-stable. In general, the stability functions of implicit RK methods are always\n",
    "rational functions, i.e., given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75821396",
   "metadata": {},
   "source": [
    "$$\n",
    "R(z) = \\frac{P(z)}{Q(z)},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7adbe8e",
   "metadata": {},
   "source": [
    "where $P, Q$ are polynomials of degree at most $s$. (Recall from the section [Stiff ODE systems and stability](#sec:stab_analysis) \n",
    "above that the stability functions for the explicit methods are always polynomials of degree at most $s$.) \n",
    "\n",
    "The accuracy of the implicit methods considered above can easily be calculated using a Taylor series expansion \n",
    "as outlined in the section [sec:error_taylor](#sec:error_taylor), and confirms that the backward Euler method is \n",
    "first order accurate while the two others are second order methods. We mentioned\n",
    "above that an explicit Runge-Kutta method with $s$ stages has order $p\\leq s$, but with implicit\n",
    "methods we have greater freedom in choosing the coefficients $a_{ij}$ and therefore potentially \n",
    "higher accuracy for a given number of stages. In fact, the maximum order for an implicit RK method\n",
    "is $p=2s$, which is precisely the case for the implicit midpoint method, having $s=1$ and $p=2$. \n",
    "We will consider more advanced implicit RK methods later, but let us first have a look at\n",
    "how we can implement the methods introduced so far. \n",
    "\n",
    "# Implementing implicit Runge-Kutta methods\n",
    "<div id=\"sec:irk_simple_impl\"></div>\n",
    "In the previous section we have demonstrated the superior stability of the implicit methods,\n",
    "and also mentioned that the accuracy is generally higher, for a fixed number of stages. \n",
    "So why are not implicit Runge-Kutta solvers the natural choice for all ODE problem? The\n",
    "answer to this question is of course the fact that they are implicit, so the stage derivatives\n",
    "are defined in terms of non-linear equations rather than explicit formulae. This fact complicates\n",
    "the implementation of the methods and makes each time step far more computationally\n",
    "expensive. Because of the latter, explicit solvers are usually more efficient for all non-stiff\n",
    "problems, and implicit solvers should only be used for stiff ODEs. \n",
    "\n",
    "For scalar ODEs, solving an equation such as ([5](#be_nonlin0)) or ([8](#imp_midpoint0)) with Newton's method\n",
    "is usually not  very challenging. However, we are most interested in solving systems of ODEs, \n",
    "which complicates the task a bit, since we then need to solve a system of coupled non-linear\n",
    "equations. Applying Newton's method to a system of equations requires the solution of a system\n",
    "of linear equations for every iteration, and we are left with a wide variety of choices for how \n",
    "to solve these, as well as other solver choices and parameters that\n",
    "may be tuned to optimize the performance. In the present text we focus on understanding the fundamental\n",
    "ideas of the IRK solvers, and we will not dive into the details of optimizing the performance. We will therefore\n",
    "base our implementation on built-in equation solvers from SciPy. We will start with the \n",
    "backward Euler method, being the simplest, but we will  \n",
    "keep the implementation sufficiently general to be easily extended to more advanced implicit \n",
    "methods. The interested reader may refer to, for instance, [[AscherPetzold;@ODEII]](#AscherPetzold;@ODEII) for \n",
    "a detailed discussion of solver optimization and choices to improve the computational performance.\n",
    "\n",
    "If we examine the `ODESolver` class first introduced in Chapter 2, we may \n",
    "observe that many of the administrative tasks involved in the RK methods are the same for \n",
    "implicit as for explicit methods. In particular, the initialization of the solution arrays\n",
    "and the for-loop that advances the solution are exactly the same, but advancing the \n",
    "solution from one step to the next is quite different. It is therefore convenient to implement the implicit solvers\n",
    "as part of the existing class hierarchy, and let the `ODESolver` superclass handle the \n",
    "tasks of initializing the solver as well as the main solver loop. The different explicit \n",
    "methods introduced in Chapter 2 where then realized through \n",
    "different implementations of the `advance` method. We can use the same approach \n",
    "for implicit methods, but since each step involves a few more operations it is\n",
    "convenient to introduce a couple of additional methods. For instance, \n",
    "a compact implementation of the backward Euler method may look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72962ef5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ODESolver import *\n",
    "from scipy.optimize import root\n",
    "\n",
    "class BackwardEuler(ODESolver):\n",
    "\n",
    "    def stage_eq(self,k):\n",
    "        u, f, n, t = self.u, self.f, self.n, self.t\n",
    "        dt = self.dt\n",
    "        return k - f(t[n]+dt,u[n]+dt*k)\n",
    "\n",
    "    def solve_stage(self):\n",
    "        u, f, n, t = self.u, self.f, self.n, self.t\n",
    "        k0 = f(t[n],u[n])\n",
    "        sol = root(self.stage_eq,k0)\n",
    "        return sol.x\n",
    "\n",
    "    def advance(self):\n",
    "        u, f, n, t = self.u, self.f, self.n, self.t\n",
    "        dt = self.dt\n",
    "        k1 = self.solve_stage()\n",
    "        return u[n]+dt*k1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c24040",
   "metadata": {},
   "source": [
    "Compared with the explicit solvers presented in Chapter 2 \n",
    "we have introduced two additional methods in our `BackwardEuler` class. \n",
    "The first of these, `stage_eq(self,k)`, is simply a Python\n",
    "implementation of ([6](#backward_euler0)), which defines the non-linear equation for the \n",
    "stage derivative. The method takes \n",
    "the stage derivative `k` as input and returns the residual of ([6](#backward_euler0)), which makes it\n",
    "suitable for use with SciPy non-linear equation solvers. The actual solution of the stage derivate equation\n",
    "is handled in the `solve_stage` method, which first computes an initial guess `k0` for the stage\n",
    "derivative, and then passes this guess and the function `stage_eq` to SciPy's `root` method for \n",
    "solving the equation. The `root` function returns an object of the class `OptimizeResult`, which includes\n",
    "the solution as an attribute `x`, as well as numerous other attributes containing information about the \n",
    "solution process. We refer to the SciPy documentation for further details on the `OptimizeResult` and the\n",
    "`root` function.\n",
    "\n",
    "<!-- dom:FIGURE: [./figs_ch3/vanderpol_be.png, width=600 frac=1] Solutions of the Van der Pol model for $\\mu=10$, using the forward and backward Euler methods with $\\Delta t = 0.04$. <div id=\"fig:vdp2\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:vdp2\"></div>\n",
    "\n",
    "<p>Solutions of the Van der Pol model for $\\mu=10$, using the forward and backward Euler methods with $\\Delta t = 0.04$.</p>\n",
    "<img src=\"./figs_ch3/vanderpol_be.png\" width=600>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "We can demonstrate the superior stability of the backward Euler method by returning to the \n",
    "Van der Pol equation considered above. Setting, for instance, $\\mu=10$, and solving the model with \n",
    "both the forward and backward Euler method gives the plots shown in [Figure](#fig:vdp2). The top panel shows\n",
    "a reference solution computed with the SciPy `solve_ivp` solver and very low tolerance (`rtol=1e-10`).\n",
    "The middle panel shows the solution produced by forward Euler with $\\Delta t = 0.04$, showing visible oscillations in \n",
    "one of the solution components. Increasing the time step further leads to a divergent solution. The lower \n",
    "panel shows the solution from backward Euler with $\\Delta t = 0.04$, which is obviously a lot more stable, \n",
    "but still quite different from the reference solution in the top panel. With the backward Euler method, \n",
    "increasing the time step further will still give a stable solution, but it does not look like the\n",
    "exact solution at all. This little experiment illustrates the need to consider both accuracy and stability \n",
    "when solving challenging ODEs systems.\n",
    "\n",
    "Just as we did for the explicit methods in Chapter 2, it is possible to reuse code from \n",
    "the `BackwardEuler` class to implement other solvers. Extensive code reuse for a large group of implicit\n",
    "solvers requires a small rewrite of the code above to a more general form, which will be presented in the next \n",
    "section. However, we may observe that a simple solver like the Crank-Nicolson method can be realized as \n",
    "a very small modification of our `BackwardEuler` class. A class implementation may look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca752f0e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CrankNicolson(BackwardEuler):\n",
    "    def advance(self):\n",
    "        u, f, n, t = self.u, self.f, self.n, self.t\n",
    "        dt = self.dt\n",
    "        k1 = f(t[n],u[n])\n",
    "        k2 = self.solve_stage()\n",
    "        return u[n]+dt/2*(k1+k2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915db36b",
   "metadata": {},
   "source": [
    "Here, we utilize the fact that the stage $k_1$ in the Crank-Nicolson is explicit and does not require\n",
    "solving an equation, while the definition of $k_2$ is identical to the definition of \n",
    "$k_1$ in the backward Euler method. We can therefore reuse both the `stage_eq` and `solve_stage` methods directly\n",
    "and only the `advance` method needs to be reimplemented. This compact implementation of the Crank-Nicolson method\n",
    "is convenient for code reuse, but it may be argued that it violates a common principle of object-oriented programming.\n",
    "Subclassing and inheritance is considered an \"is-a\" relationship, so this class implementation implies that an instance\n",
    "of the `Crank-Nicolson` class is also an instance of the `BackwardEuler` class. While this works fine in the program, \n",
    "and is convenient for code reuse, it is not a correct representation of the relationship between the two \n",
    "numerical methods. The Crank-Nicolson method is not a special case of the backward Euler, but, as noted above, \n",
    "both methods belong to the group of implicit RK solvers. In the following sections we will \n",
    "describe an alternative class hierarchy which is based on this relationship, and enables a compact \n",
    "implementation of RK methods by utilizing the general formulation in ([genrk0](#genrk0))-([genrk1](#genrk1))\n",
    "\n",
    "\n",
    "# Implicit methods of higher order\n",
    "Just as for the ERK methods considered in Chapter 2, the accuracy of IRK methods\n",
    "can be increased by adding more stages. However, for implicit methods we have even more\n",
    "freedom in choosing the parameters $a_{ij}$, and the choice of these impacts both the\n",
    "accuracy and the computational complexity of the methods. We will here consider two \n",
    "main branches of IRK methods; the so-called *fully implicit* methods and the *diagonally implicit* methods. \n",
    "Both classes of methods are quite popular and commonly used, and both have their advantages and drawbacks.\n",
    "\n",
    "## Fully implicit RK methods\n",
    " The most general form of RK methods are the fully implicit methods, often referred to as\n",
    "FIRK methods. These solvers are simply defined by ([genrk0](#genrk0))-([genrk1](#genrk1)), with all\n",
    "coefficients $a_{ij}$ (potentially) non-zero. For a method with more than one stage, \n",
    "this formulation implies that all stage derivatives depend on all other stage derivatives,\n",
    "so we need to determine them all at once by solving a single system of non-linear \n",
    "equations. This operation is quite expensive, but the reward is that the FIRK methods have\n",
    "superior stability and accuracy for a given number of stages. A FIRK method with \n",
    "$s$ stages can have order at most $2s$, which was the case for the implicit midpoint\n",
    "method in ([8](#imp_midpoint0))-([9](#imp_midpoint1)).\n",
    "\n",
    "!Many of the most popular FIRK methods are based on combining standard quadrature \n",
    "methods for numerical integration with the idea of *collocation*. We present the\n",
    "basic idea of the derivation here, since many important methods are based on the\n",
    "same foundation. For the complete details we refer ti, for instance, [[ODEII]](#ODEII).\n",
    "Recall from Chapter 2 that all Runge-Kutta methods\n",
    "can be viewed as approximations of ([ode_integral0](#ode_integral0)), where\n",
    "the integral is approximated by a weighted sum. We set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456d49c",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"ode_integral_approx\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    u(t_{n+1}) &= u(t_n) + \\int_{t_n}^{t_{n+1}} f(t,u(t)) \\approx u(t_n) + \\sum_{i=1}^s b_i k_i ,\n",
    "    \\label{ode_integral_approx} \\tag{14}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b34b6",
   "metadata": {},
   "source": [
    "where $b_i$ are the weights and $k_i$ are the stage derivatives, which \n",
    "could be interpreted as approximations of the right-hand side function $f(t,u)$ at distinct \n",
    "time points $t_n+\\Delta t c_i$. \n",
    "\n",
    "Numerical integration is a very well studied branch of \n",
    "numerical analysis, and it is natural to choose the integration\n",
    "points $c_i$ and weights $b_i$ based on standard quadrature rules\n",
    "with well established properties. Such quadrature rules are often derived\n",
    "by approximating the integrand with a polynomial which interpolates the function \n",
    "$f$ in distinct points, and then integrating the\n",
    "polynomial exactly. The same idea can be used in the derivation\n",
    "of implicit RK methods. We approximate the solution \n",
    "$u$ on the interval $t_n < t \\leq t_{n+1}$ by a polynomial $P(t)$ of \n",
    "degree at most $s$, and then require that $P(t)$ solves the ODE exactly in\n",
    "distinct points $t_n+c_i\\Delta t$. This requirement, i.e., that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ee42b",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"colloc0\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "P'(t_i) = f(t_i,P(t_i)), \\quad  t_i = t_n+c_i\\Delta t, i = 1,\\ldots , s .\n",
    "\\label{colloc0} \\tag{15}\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8528280f",
   "metadata": {},
   "source": [
    "is known as collocation, and is a widely used idea in numerical analysis. \n",
    "It can be shown that, given a choice of quadrature points $c_i$, \n",
    "the collocation equations given by ([15](#colloc0)) determines the remaining method coefficients $a_{ij}$ \n",
    "and $b_i$ uniquely, see [[AscherPetzold]](#AscherPetzold) for details. \n",
    "\n",
    "A convenient way to \n",
    "derive FIRK methods is to choose a set of collocation points $c_i$, typically\n",
    "chosen from standard quadrature rules, and solve ([15](#colloc0))\n",
    "to determine the remaining parameters. This approach has led to families of FIRK methods based on \n",
    "common rules for numerical integration. For instance, choosing $c_i$ as Gauss points\n",
    "gives rise to the Gauss methods, which are the most accurate methods for a given number\n",
    "of stages, having order $2s$.\n",
    "The single stage Gauss method is the implicit midpoint method introduced above, \n",
    "while the fourth order Gauss method with $s=2$ is defined by the Butcher tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0253a5c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c|cc}\n",
    "    \\frac{3-\\sqrt{3}}{6} &\\frac{1}{4} & \\frac{3-2\\sqrt{3}}{12}\\\\\n",
    "    \\frac{3+\\sqrt{3}}{6}  & \\frac{3+2\\sqrt{3}}{12} & \\frac{1}{4} \\\\ \\hline\n",
    "     & \\frac{1}{2}& \\frac{1}{2}\n",
    "    \\end{array} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe5810",
   "metadata": {},
   "source": [
    "The Gauss methods are A-stable but not L-stable, and since we typically only use\n",
    "FIRK methods for challenging stiff problems where stability is important, another\n",
    "family of FIRK methods is more popular in practice. These are the Radau IIA methods, \n",
    "which are based on Radau quadrature points which include the right end of the \n",
    "integration interval (i.e., $c_s = 1$). The one-stage Radau IIA method is the backward \n",
    "Euler method, while two- and three-stage versions are given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c7ce14",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c|cc}\n",
    "    1/3 &5/12 & -1/12\\\\ \n",
    "    1 & 3/4 & 1/4 \\\\ \\hline\n",
    "     & 2/3& 1/4\n",
    "    \\end{array} , \\hspace{1.0cm}\n",
    "    \\begin{array}{c|ccc}\n",
    "        \\frac{4-\\sqrt{6}}{10} &\\frac{88-7\\sqrt{6}}{360} & \\frac{296-169\\sqrt{6}}{1800}&\\frac{-2+3\\sqrt{6}}{225}\\\\\n",
    "        \\frac{4+\\sqrt{6}}{10} & \\frac{296+169\\sqrt{6}}{1800} & \\frac{88+7\\sqrt{6}}{360} & \\frac{-2-3\\sqrt{6}}{225} \\\\ \n",
    "        1 & \\frac{16-\\sqrt{6}}{36} & \\frac{16+\\sqrt{6}}{36} & \\frac{1}{9} \\\\ \\hline\n",
    "        & \\frac{16-\\sqrt{6}}{36} & \\frac{16+\\sqrt{6}}{36} & \\frac{1}{9} \\\\ \n",
    "        \\end{array} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e0abda",
   "metadata": {},
   "source": [
    "The Radau IIA methods have order $s-1$, and their stability functions are $(s-1,s)$ Pad√© approximations\n",
    "to the exponential function [[ODEII]](#ODEII). For the two- and three-stage methods\n",
    "above, the stability functions are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c68811",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "R(z) &= \\frac{1+z/3}{1-2z/3 +z^2/6} ,\\\\\n",
    "R(z) &= \\frac{1+2z/5+z^2/20}{1-3z/5 +3z^2/20-z^2/60}, \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3433a17",
   "metadata": {},
   "source": [
    "respectively, with stability domains shown in [Figure](#fig:stab_radau).\n",
    "The methods are L-stable, which makes them a popular choice for solving \n",
    "stiff ODE systems. However, as noted above, the fact that all $a_{ij} \\neq 0$ complicates \n",
    "the implementation of the methods and makes each time step computationally expensive. All the\n",
    "$s$ equations of ([genrk0](#genrk0)) become fully coupled and need to be solved simultaneously. \n",
    "For an ODE system consisting of $m$ ODEs, we need to solve a system of $m s$ non-linear\n",
    "equations for each time step. We will come back the implementation of FIRK methods in \n",
    "the section [Implementing higher order IRK methods](#sec:irk_implementation), but let us first introduce a slightly simpler class \n",
    "of implicit RK solvers. \n",
    "\n",
    "\n",
    "<!-- dom:FIGURE: [./figs_ch3/stab_region_radau.png, width=600 frac=1] The shaded area is the stability region for two of the RadauIIA methods, with $s=2$ (left) and $s=3$ (right). <div id=\"fig:stab_radau\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:stab_radau\"></div>\n",
    "\n",
    "<p>The shaded area is the stability region for two of the RadauIIA methods, with $s=2$ (left) and $s=3$ (right).</p>\n",
    "<img src=\"./figs_ch3/stab_region_radau.png\" width=600>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "\n",
    "## Diagonally implicit RK methods\n",
    " Diagonally implicit RK methods, or DIRK methods for short, are also sometimes also \n",
    "referred to as semi-explicit methods. For these methods, we have $a_{ij} = 0$ for\n",
    "all $j>i$. (Notice the small but important difference from the explicit methods,\n",
    "where we have $a_{ij} = 0$ for $j\\geq i$.) The consequence of this\n",
    "choice is that the equation for a single stage derivative $k_i$ \n",
    "does not involve stages $k_{i+1}, k_{i+2}$, and so forth, and we can therefore solve \n",
    "for the stage derivatives one by one sequentially. We still need to solve\n",
    "non-linear equations to determine each $k_i$, but we can solve $s$ systems of $m$\n",
    "equations rather than one large system to compute all the stages at once. This \n",
    "property simplifies the implementation and reduces the computational expense \n",
    "per time step. However, as expected, the restriction on the method coefficients \n",
    "reduces the accuracy and stability compared with the FIRK methods. \n",
    "A general DIRK method with $s$ stages has maximum order $s+1$, and methods optimized for stability \n",
    "typically have even lower order. \n",
    "\n",
    "From the definition of the DIRK methods, we may observe that the implicit midpoint method\n",
    "introduced above is, technically, a DIRK method. However, is method is also a fully implicit\n",
    "Gauss method, and is not commonly referred to as a DIRK method. The distinction between FIRK and DIRK methods\n",
    "is only meaningful for $s>1$. The\n",
    "Crank-Nicolson (implicit trapezoidal) method given by ([10](#cn_0))-([12](#cn_2)) is \n",
    "also a DIRK method, which is evident from the leftmost Butcher tableau in ([13](#irk_butcher0)). \n",
    "These methods are, however, only A-stable, and it is possible to derive DIRK methods with\n",
    "better stability properties. An example of an L-stable, two-stage DIRK method of order two is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf39a46f",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"dirk2_v0\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{array}{c|cc}\n",
    "    \\gamma &\\gamma & 0 \\\\\n",
    "    1  & 1-\\gamma& \\gamma\\\\ \\hline\n",
    "     & 1-\\gamma& \\gamma\n",
    "    \\end{array} ,\n",
    "\\label{dirk2_v0} \\tag{16}\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7135faaa",
   "metadata": {},
   "source": [
    "with $\\gamma = 1\\pm \\sqrt(2)/2$. The stability function is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa6145",
   "metadata": {},
   "source": [
    "$$\n",
    "R(z) = \\frac{1+z(1-2\\gamma)}{(1-z\\gamma)^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbc14b",
   "metadata": {},
   "source": [
    "and are A-stable for $\\gamma >1/4$. For $\\gamma = 1\\pm \\sqrt(2)/2$ the method is L-stable and \n",
    "second order accurate. Note that \n",
    "choosing $\\gamma > 1$ means that we estimate the stage derivatives outside the \n",
    "interval $(t_n,t_{n+1})$, and for the last step outside the time interval of interest. \n",
    "While this does not affect the stability or accuracy of the method it may not make sense\n",
    "for all ODE problems, and the most popular choice is therefore $\\gamma = 1-\\sqrt(2)/2$.\n",
    "Notice also that in this method the two diagonal entries of $a_{ij}$ \n",
    "are identical, we have $a_{11}=a_{22}=\\gamma$. This choice is very common in DIRK\n",
    "methods, and methods of this kind are usually referred to as *singly diagonally\n",
    "implicit* RK (SDIRK) methods. The main benefit of this structure is that \n",
    "the non-linear equations for each stage derivative become very similar, which\n",
    "we can take advantage of when solving the equations with quasi-Newton methods.\n",
    "In particular, the systems will have the same Jacobian matrix, which can \n",
    "then be reused for all stages. \n",
    "\n",
    "\n",
    "While we do not aim to present a complete overview of the various sub-categories\n",
    "of RK methods, one additional class of method is worth mentioning. These are\n",
    "the so called ESDIRK methods, which are simply SDIRK methods where the first stage\n",
    "is explicit. The motivation for such methods is that the non-linear algebraic equations\n",
    "involved in the implicit methods are always solved with iterative methods, which\n",
    "require an initial guess for the solution. For SDIRK methods, it is convenient to\n",
    "use the previous stage derivate as initial guess for the next one, which will usually provide \n",
    "a good initial guess. This approach is obviously not possible for the first stage, but an \n",
    "explicit formula for the first stage solves this problem. The simplest ESDIRK method is the implicit trapezoidal (Crank-Nicolson) method\n",
    "introduced above, and a popular extension of this method is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5164a15b",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"butcher-tr-bdf2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{array}{c|ccc}\n",
    "    0 & 0&  & \\\\\n",
    "    2\\gamma & \\gamma & \\gamma & 0\\\\ \n",
    "    1 & \\beta & \\beta & \\gamma \\\\ \\hline\n",
    "     & \\beta & \\beta & \\gamma \\\\\n",
    "    \\end{array} ,\\hspace{0.5cm} \n",
    "    \\label{butcher-tr-bdf2} \\tag{17}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73dcbc",
   "metadata": {},
   "source": [
    "with $\\gamma = 1-\\sqrt{2}/2$ and $\\beta = \\sqrt{2}/4$. The resulting equations for each time step are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5415676",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "k_1 &= f(t_n, u_n),\\\\ \n",
    "k_2 &= f(t_n+2\\gamma\\Delta t,u_n+\\Delta t(\\gamma k_1 + \\gamma k_2)), \\\\\n",
    "k_3 &= f(t_n+\\Delta t,u_n+\\Delta t(\\beta k_1 + \\beta k_2+\\gamma k_3)), \\\\\n",
    "u_{n+1} &= u_n + \\Delta t (\\beta k_1 +\\beta k_2+ \\gamma k_3) . \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546a9da5",
   "metadata": {},
   "source": [
    "This method can be interpreted as the sequential \n",
    "application of the trapezoidal method and a popular multistep solver called BDF2 \n",
    "(*backward differentiation formula* of order 2), and it is commonly referred\n",
    "to as the TR-BDF2 method. It is second order accurate, just as the trapezoidal rule, but it \n",
    "is also L-stable and therefore suitable for stiff problems. \n",
    "\n",
    "# Implementing higher order IRK methods\n",
    "<div id=\"sec:irk_implementation\"></div>\n",
    "In the section [Implementing implicit Runge-Kutta methods](#sec:irk_simple_impl) we implemented two of the simplest implicit RK methods by a relatively \n",
    "small extension of the `ODEsolver` class hierarchy. We could easily continue this idea for the more complex\n",
    "IRK methods, and all the different methods could be realized by separate implementations of the three methods \n",
    "`solve_stage`, `stage_eq`, and `advance`. However, these three methods essentially implement the\n",
    "equations given by ([genrk0](#genrk0))-([genrk1](#genrk1)), which are common for all RK solvers. It is natural\n",
    "to look for an implementation that allows even more code reuse between the various methods, and we shall see\n",
    "that such a general implementation is indeed possible. However, it still makes sense to treat the\n",
    "fully implicit methods and SDIRK methods separately, since the stage calculations of these two method classes are\n",
    "fundamentally different. \n",
    "\n",
    "## A base class for fully implicit methods\n",
    "One approach to implement the fully implicit RK methods is to rewrite the \n",
    "`solve_stage`, `stage_eq`, and `advance` methods of the \n",
    "`BackwardEuler` class  above in a completely general manner, so they can handle any number of stages and any choice of\n",
    "method parameters $a_{ij},b_i$, and $c_i$. New methods can then be implemented simply by setting the number of stages and \n",
    "defining the parameter values. In the methods considered so far all the method coefficients have been \n",
    "hard-coded into the mathematical expressions, typically inside the `advance` methods, but with the generic approach\n",
    "it is natural to define them as class attributes in the constructor. A general base class for implicit RK\n",
    "methods may look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63dbdfdb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ImplicitRK(ODESolver):\n",
    "    def solve_stages(self):\n",
    "        u, f, n, t = self.u, self.f, self.n, self.t\n",
    "        neq = self.neq\n",
    "        s = self.stages\n",
    "        k0 = f(t[n],u[n]) \n",
    "        k0 = np.hstack([k0 for i in range(s)])\n",
    "        \n",
    "        sol = root(self.stage_eq,k0) \n",
    "\n",
    "        return np.split(sol.x,s)\n",
    "\n",
    "    def stage_eq(self,k_all):\n",
    "        a,c = self.a, self.c \n",
    "        s, neq = self.stages, self.neq\n",
    "\n",
    "        u, f, n, t = self.u, self.f, self.n, self.t\n",
    "        dt = self.dt\n",
    "\n",
    "        res = np.zeros_like(k_all)\n",
    "        k = np.split(k_all,s)\n",
    "        for i in range(s):\n",
    "            fi = f(t[n]+c[i]*dt, \n",
    "                   u[n]+dt*sum([a[i,j]*k[j] for j in range(s)]))\n",
    "            res[i*neq:(i+1)*neq] = k[i] - fi \n",
    "                                            \n",
    "        return res\n",
    "\n",
    "    def advance(self):\n",
    "        b = self.b \n",
    "        u, n, t = self.u, self.n, self.t\n",
    "        dt = self.dt\n",
    "        k = self.solve_stages()\n",
    "        \n",
    "        return u[n]+dt*sum(b_*k_ for b_,k_ in zip(b,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34c908",
   "metadata": {},
   "source": [
    "Note that we assume that the method parameters are assumed to be held in NumPy arrays \n",
    "`self.a, self.b, self.c`, which need to be defined in subclasses. The `ImplicitRK` class\n",
    "is meant to be a pure base class for holding common code, and is not intended to be a usable solver\n",
    "class in itself. The three methods are generalizations of the\n",
    "same methods in `BackwardEuler` class, and perform the same tasks, but the abstraction level is higher and \n",
    "the methods rely on a bit of NumPy magic: \n",
    "* The `solve_stages` method is obviously a generalization of the `solve_stage` method above, and most of the\n",
    "  lines are quite similar and should be self-explanatory. However, be aware that we are now implementing a general\n",
    "  IRK method with $s$ stages, and we solve a single system of non-linear equations to determine all $s$ stage\n",
    "  derivatives at once. The solution of this system is a one-dimensional array of length \n",
    "  `self.stages * self.neq`, which contains all the stage derivatives. The line `k0 = np.hstack([k0 for i in range(s)])`\n",
    "  takes an initial guess `k0` for a single stage, and simply stacks it after itself $s$ times to create the initial guess\n",
    "  for all the stages, using NumPy's `hstack` function and a list comprehension. \n",
    "\n",
    "* The `stage_eq` method is also a pure generalization of the `BackwardEuler` version, and performs the same tasks. \n",
    "  The first few lines should be self-explanatory, while the `res = np.zeros_like(k_all)` defines an array of the \n",
    "  correct length to hold the residual of the equation. Then, for convenience, the line `k = np.split(k_all,s)` \n",
    "  splits the array `k_all` into a list `k` containing the individual stage derivatives, which is used inside\n",
    "  the for loop on the next four lines. This loop forms the core of the method, and \n",
    "  is essentially just ([genrk0](#genrk0)) implemented in Python code, split over several lines for improved readability.  \n",
    "  The residual is returned as a single array of length `self.stages * self.neq`, as expected by the SciPy `root` function.\n",
    "\n",
    "* Finally, the `advance` method calls the `solve_stages` to compute all the stage derivatives, and then advances\n",
    "  the solution using a general implementation of ([genrk1](#genrk1)).\n",
    "\n",
    "With the general base class at hand, we can easily implement new solvers, simply by writing the constructors\n",
    "that define the method coefficients. The following code implements the implicit midpoint and the two- and\n",
    "three-stage Radau methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b221f2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ImpMidpoint(ImplicitRK):\n",
    "    def __init__(self,f):\n",
    "        super().__init__(f)\n",
    "        self.stages = 1\n",
    "        self.a = np.array([[1/2]])\n",
    "        self.c = np.array([1/2])\n",
    "        self.b = np.array([1])\n",
    "\n",
    "\n",
    "class Radau2(ImplicitRK):      \n",
    "    def __init__(self,f):\n",
    "        super().__init__(f)\n",
    "        self.stages = 2\n",
    "        self.a = np.array([[5/12,-1/12],[3/4,1/4]])\n",
    "        self.c = np.array([1/3,1])\n",
    "        self.b = np.array([3/4, 1/4])\n",
    "\n",
    "\n",
    "class Radau3(ImplicitRK):\n",
    "    def __init__(self,f):\n",
    "        super().__init__(f)\n",
    "        self.stages = 3\n",
    "        sq6 = np.sqrt(6)\n",
    "        self.a = np.array([ [(88-7*sq6)/360,\n",
    "                            (296-169*sq6)/1800,\n",
    "                            (-2+3*sq6)/(225)],\n",
    "                            [(296+169*sq6)/1800, \n",
    "                            (88+7*sq6)/360,\n",
    "                            (-2-3*sq6)/(225)],\n",
    "                            [(16-sq6)/36, (16+sq6)/36,1/9]])\n",
    "        self.c = np.array([(4-sq6)/10,(4+sq6)/10,1])\n",
    "        self.b = np.array([(16-sq6)/36, (16+sq6)/36,1/9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16592f",
   "metadata": {},
   "source": [
    "Notice that we always define the method coefficients as NumPy arrays, even for the\n",
    "implicit midpoint method where they all contain a single number. This definition is\n",
    "necessary for the generic methods of the `ImplicitRK` class to work. \n",
    "\n",
    "## Base classes for SDIRK and ESDIRK methods\n",
    "We could, in principle, implement both the SDIRK and ESDIRK \n",
    "methods in the same manner as the FIRK methods above, simply by defining\n",
    "the method coefficients in the constructor. The generic methods from the\n",
    "`ImplicitRK` base class will work fine even if we have $a_{ij} = 0$ \n",
    "for $j>i$. However, the motivation for deriving diagonally implicit methods is precisely to\n",
    "avoid solving these large systems of non-linear equations, so it does not make much\n",
    "sense to implement them in this way. Instead, we should utilize the structure of \n",
    "the method coefficients and solve for the stage variables sequentially. \n",
    "This requires rewriting the two methods `solve_stages` and `stage_eq` from the\n",
    "base class above. Once the stage derivatives have been computed, advancing the\n",
    "solution to the next step occurs in the same way for all RK methods, \n",
    "so the `advance` method can be left unchanged. \n",
    "\n",
    "Considering first the SDIRK methods, we can implement these as \n",
    "subclasses of the `ImplicitRK` class, which\n",
    "enables some (moderate) code reuse and reflects the fact that SDIRK methods are indeed\n",
    "special cases of implicit RK methods. Using the two-stage SDIRK method defined by ([16](#dirk2_v0)) as an example, \n",
    "we get a better view of the tasks involved in the SDIRK methods if we write out the equations for the\n",
    "stage derivatives. Inserting the coefficients from ([16](#dirk2_v0)) into \n",
    "([genrk0](#genrk0))-([genrk1](#genrk1)) gives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60fce8",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"dirk2_eq0\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "k_1 = f(t_n+\\gamma\\Delta t, u_n+\\Delta t \\gamma k_1), \\label{dirk2_eq0} \\tag{18}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b269cb",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"dirk2_eq1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "k_2 = f(t_n+\\Delta t,u_n+\\Delta t((1-\\gamma)k_1 + \\gamma k_2)), \\label{dirk2_eq1} \\tag{19}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29643f",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"dirk2_eq2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "u_{n+1} = u_n + \\Delta t ((1-\\gamma)k_1 +\\gamma k_2) . \\label{dirk2_eq2} \\tag{20}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ca95f",
   "metadata": {},
   "source": [
    "Here, ([18](#dirk2_eq0)) is nearly identical to the equation defining the stage derivative\n",
    "in the backward Euler method, the only difference being the factor $\\gamma$ \n",
    "in front of the arguments inside the function call. Furthermore, the only difference between ([18](#dirk2_eq0)) and\n",
    "([19](#dirk2_eq1)) is the additional term $\\Delta t(1-\\gamma)k_1$ inside the function call. \n",
    "In general, any stage equation for any DIRK method can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd0ec2",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"sdirk_stage\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "k_i = f(t_n+c_i\\Delta t, u_n+\\Delta t(\\sum_{j=0}^{i-1}a_{ij}k_j + \\gamma k_i)), \\label{sdirk_stage} \\tag{21}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74d289",
   "metadata": {},
   "source": [
    "where the sum inside the function call only includes previously computed stages. \n",
    "\n",
    "Given the similarity of ([21](#sdirk_stage)) with the stage equation from the backward Euler method, \n",
    "it is natural to implement the SDIRK stage equation as a generalization of the `stage_eq` \n",
    "method from the `BackwardEuler` class. It is also convenient to place this method in an SDIRK\n",
    "base class, from which we may derive all specific SDIRK solver classes. \n",
    "Furthermore, since the stage equations can be written on this general form, it is not difficult\n",
    "to generalize the algorithm for looping through the stages and computing the individual \n",
    "stage derivatives. The base class can, therefore, contain general SDIRK versions of both the `stage_eq`\n",
    "and `solve_stages`, and the only task left in individual solver classes is to define the number\n",
    "of stages and the method coefficients. The complete base class implementation may look as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e5489d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SDIRK(ImplicitRK):\n",
    "    def stage_eq(self,k,c_i, k_sum):\n",
    "        u, f, n, t = self.u, self.f, self.n, self.t\n",
    "        dt = self.dt\n",
    "        gamma = self.gamma\n",
    "\n",
    "        return k - f(t[n]+c_i*dt,u[n]+dt*(k_sum+gamma*k))\n",
    "\n",
    "    def solve_stages(self):\n",
    "        u, f, n, t = self.u, self.f, self.n, self.t\n",
    "        a, c = self.a, self.c    \n",
    "        s = self.stages\n",
    "\n",
    "        k = f(t[n],u[n]) #initial guess for first stage\n",
    "        k_sum = np.zeros_like(k)\n",
    "        k_all = []\n",
    "        for i in range(s):\n",
    "            k_sum = sum(a_*k_ for a_,k_ in zip(a[i,:i],k_all))\n",
    "            k = root(self.stage_eq,k,args=(c[i],k_sum)).x\n",
    "            k_all.append(k)\n",
    "        \n",
    "        return k_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e61f608",
   "metadata": {},
   "source": [
    "The modified `stage_eq` method takes two additional parameters; the coefficient `c_i` corresponding to the current stage, \n",
    "and the array `k_sum` which holds the sum $\\sum_{j=1}^{i-1}a_{ij}k_j$. These arguments need to be\n",
    "initialized correctly for each stage, and passed as additional arguments to the SciPy `root` function. \n",
    "For convenience, we also assume that the method parameter $\\gamma$ has been stored as a separate \n",
    "class attribute. With the `stage_eq` method implemented in this general way, the `solve_stages` method \n",
    "simply needs to update the weighted sum of previous stages (`k_sum`), and pass this and the correct $c$ value\n",
    "as additional arguments to the SciPy `root` function. The implementation above implements this in a for loop\n",
    "which computes the stage derivatives sequentially and returns them as a list `k_all`. \n",
    "\n",
    "\n",
    "<!-- dom:FIGURE: [./figs_ch3/vanderpol_irk.png, width=600 frac=1] Solutions of the Van der Pol model for $\\mu=10$ and $\\Delta t = 0.1$, using implicit RK solvers of different accuracy. <div id=\"fig:vanderpol_irk\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:vanderpol_irk\"></div>\n",
    "\n",
    "<p>Solutions of the Van der Pol model for $\\mu=10$ and $\\Delta t = 0.1$, using implicit RK solvers of different accuracy.</p>\n",
    "<img src=\"./figs_ch3/vanderpol_irk.png\" width=600>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "As for the FIRK method classes, the only method we now need to implement specifically for each solver class is the\n",
    "constructor, in which we define the number of stages and the method coefficients. A class implementation of the\n",
    "method in ([16](#dirk2_v0)) may look as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "521e637d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SDIRK2(SDIRK):\n",
    "    def __init__(self,f):\n",
    "        super().__init__(f)\n",
    "        self.stages = 2\n",
    "        gamma = (2-np.sqrt(2))/2\n",
    "        self.gamma = gamma\n",
    "        self.a = np.array([[gamma,0],\n",
    "                            [1-gamma, gamma]])\n",
    "        self.c = np.array([gamma,1])\n",
    "        self.b = np.array([1-gamma, gamma])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70814b0",
   "metadata": {},
   "source": [
    "Shifting our attention to the ESDIRK methods, these are identical to the SDIRK methods except for the\n",
    "first stage, and the potential for code reuse is obvious. Examining the two methods of the \n",
    "SDIRK base class above, we quickly conclude that the `stage_eq` method can be reused in an ESDIRK solver\n",
    "class, since the equations to be solved for each stage are identical for SDIRK and ESDIRK solvers. \n",
    "However, the `solve_stages` method needs to be modified, since there is no need to solve a non-linear\n",
    "equation for `k1`. The modifications can, however, be very small, since all stages $i>1$ are identical. \n",
    "A possible implementation of the ESDIRK class can look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615e1a85",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ESDIRK(SDIRK):\n",
    "    def solve_stages(self):\n",
    "        u, f, n, t = self.u, self.f, self.n, self.t\n",
    "        a, c = self.a, self.c    \n",
    "        s = self.stages\n",
    "\n",
    "        k = f(t[n],u[n]) \n",
    "        k_sum = np.zeros_like(k)\n",
    "        k_all = [k]\n",
    "        for i in range(1,s):\n",
    "            k_sum = sum(a_*k_ for a_,k_ in zip(a[i,:i],k_all))\n",
    "            k = root(self.stage_eq,k,args=(c[i],k_sum)).x\n",
    "            k_all.append(k)\n",
    "\n",
    "        return k_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf813cc",
   "metadata": {},
   "source": [
    "Comparing with the SDIRK base class above, the two methods look identical at first, but there are two small but important \n",
    "differences. The first is that the result of the first function \n",
    "evaluation `k = f(t[n],u[n])` is now used directly as the first stage, by setting `k_all = [k]`, \n",
    "instead of just serving as an initial guess for the nonlinear equation solver. \n",
    "The second is that the for-loop for computing the remaining stages starts at `i=1` rather than `i=0`. \n",
    "\n",
    "With the ESDIRK base class at hand, we can implement individual ESDIRK methods simply by defining the\n",
    "constructor, for instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e1c008",
   "metadata": {},
   "source": [
    "        class BDF_TR2(ESDIRK):\n",
    "            def __init__(self,f):\n",
    "                super().__init__(f)\n",
    "                self.stages = 3\n",
    "                gamma = 1-np.sqrt(2)/2\n",
    "                beta = np.sqrt(2)/4\n",
    "                self.gamma = gamma\n",
    "                self.a = np.array([[0,0,0],\n",
    "                                    [gamma, gamma,0],\n",
    "                                    [beta,beta,gamma]])\n",
    "                self.c = np.array([0,2*gamma,1])\n",
    "                self.b = np.array([beta,beta,gamma])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400dda86",
   "metadata": {},
   "source": [
    "Notice that these class implementations have some potential weaknesses. An obvious one is that the `solve_stages` methods\n",
    "of the SDIRK and ESDIRK classes are nearly identical, and most of the code is duplicated. Part of the purpose\n",
    "of implementing the solvers in a class hierarchy is to avoid code duplication, so this is obviously not optimal. However, \n",
    "avoiding duplicated code completely would in this case require refactoring the classes a bit, to split the\n",
    "tasks performed in `solve_stages` into several methods. Since these tasks belong quite naturally together, splitting\n",
    "them up could make the code more difficult to read and understand, and would also potentially make the code \n",
    "less computationally efficient. The latter should always be a consideration when implementing numerical methods, \n",
    "although it is not a strong focus of the present text. \n",
    "\n",
    "Another choice that can be questioned in the `ESDIRK` classis that we retain the \n",
    "dimensions of the `self.a` coefficient array, and simply set the entire first row to zero. Storing these zeros is obviously \n",
    "not needed, and we could have omitted them and adjusted the for-loop in `solve_stages` accordingly. However, this choice\n",
    "would make the link between the code and the mathematical formulation of RK methods less obvious, and the benefits would \n",
    "be minimal. \n",
    "\n",
    "[Figure](#fig:vanderpol_irk) illustrates the difference in accuracy between a number of IRK solvers. The \n",
    "chosen time step $\\Delta t = 0.1$ is obviously too large for the backward Euler method, \n",
    "and the solution is not even close to the reference solution. The other solvers are the three-stage SDIRK method of order\n",
    "two, the two-stage Radau method of order three, and three-stage Radau method of order five. \n",
    "We will see more examples of SDIRK methods in Chapter 4, when we introduce RK methods with adaptive time step."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
